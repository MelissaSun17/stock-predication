{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-03T14:00:46.640825Z","iopub.execute_input":"2021-12-03T14:00:46.641392Z","iopub.status.idle":"2021-12-03T14:00:46.680455Z","shell.execute_reply.started":"2021-12-03T14:00:46.641263Z","shell.execute_reply":"2021-12-03T14:00:46.679606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nfrom math import sqrt","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:00:48.909638Z","iopub.execute_input":"2021-12-03T14:00:48.909925Z","iopub.status.idle":"2021-12-03T14:00:55.763778Z","shell.execute_reply.started":"2021-12-03T14:00:48.909896Z","shell.execute_reply":"2021-12-03T14:00:55.76274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/nyse/prices-split-adjusted.csv')\ndf2 = df[df.symbol == 'NFLX']\ndf2.drop(['symbol'],1,inplace = True)\ndf2.set_index(['date'],inplace = True) # convert the date into index\ndf2","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:00:55.765535Z","iopub.execute_input":"2021-12-03T14:00:55.765772Z","iopub.status.idle":"2021-12-03T14:00:57.348418Z","shell.execute_reply.started":"2021-12-03T14:00:55.765742Z","shell.execute_reply":"2021-12-03T14:00:57.34757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalize Data**","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range = (0,1))\nsc_X = scaler.fit_transform(df2.values)\nprint(sc_X)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:00:59.694702Z","iopub.execute_input":"2021-12-03T14:00:59.69501Z","iopub.status.idle":"2021-12-03T14:00:59.704717Z","shell.execute_reply.started":"2021-12-03T14:00:59.694974Z","shell.execute_reply":"2021-12-03T14:00:59.703387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_len = 7 # use the previous 7 days' value to predict the 8th day's close value\ndef dataset(data, seq_len):\n    X, y = [], []\n    for i in range(len(data) - seq_len):\n        lis = data[i:(i + seq_len), 0]\n        X.append(lis)\n        y.append(data[i + seq_len, 0])\n    return np.array(X), np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:01:02.544032Z","iopub.execute_input":"2021-12-03T14:01:02.544339Z","iopub.status.idle":"2021-12-03T14:01:02.551469Z","shell.execute_reply.started":"2021-12-03T14:01:02.544305Z","shell.execute_reply":"2021-12-03T14:01:02.550827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create training and test sets**","metadata":{}},{"cell_type":"code","source":"train_size = int(len(sc_X)*0.8)\ntest_size = len(sc_X) - train_size\n\ntrain,test = sc_X[0:train_size,:], sc_X[train_size:len(sc_X),:]\ntrain_X, train_y = dataset(train, seq_len)\ntest_X, test_y = dataset(test, seq_len)\n\ntrain_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\ntest_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\nprint(train_y)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:01:13.466809Z","iopub.execute_input":"2021-12-03T14:01:13.467095Z","iopub.status.idle":"2021-12-03T14:01:13.480581Z","shell.execute_reply.started":"2021-12-03T14:01:13.467061Z","shell.execute_reply":"2021-12-03T14:01:13.479592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:01:15.592708Z","iopub.execute_input":"2021-12-03T14:01:15.592969Z","iopub.status.idle":"2021-12-03T14:01:15.599744Z","shell.execute_reply.started":"2021-12-03T14:01:15.592941Z","shell.execute_reply":"2021-12-03T14:01:15.598732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Build the model**","metadata":{}},{"cell_type":"code","source":"\nmodel = Sequential () \n\nmodel.add(LSTM(256, input_shape=(seq_len,1), return_sequences=True))\nmodel.add(LSTM(128,return_sequences=False))\nmodel.add(Dense(1, activation = 'linear')) \nmodel.compile(loss='mse',optimizer='adam', metrics=['mae'])\nhistory = model.fit(train_X,train_y,batch_size=512, epochs=90,verbose=1)\n#score = model.evaluate(test_X,test_y, batch_size = 64, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:01:17.570667Z","iopub.execute_input":"2021-12-03T14:01:17.570951Z","iopub.status.idle":"2021-12-03T14:02:02.871915Z","shell.execute_reply.started":"2021-12-03T14:01:17.570922Z","shell.execute_reply":"2021-12-03T14:02:02.871183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:23:04.981855Z","iopub.execute_input":"2021-12-03T13:23:04.982377Z","iopub.status.idle":"2021-12-03T13:23:04.989408Z","shell.execute_reply.started":"2021-12-03T13:23:04.98234Z","shell.execute_reply":"2021-12-03T13:23:04.987942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Make prediction and denormalize the predicted values**","metadata":{}},{"cell_type":"code","source":"scaler2 = MinMaxScaler()\nclose = df2['close'].values.reshape(-1,1)\nclose_denorm = scaler2.fit_transform(close)\n\ntest_pred_y = model.predict(test_X) # 346,1\ntest_pred_y = scaler2.inverse_transform(test_pred_y.reshape(-1,1))\n\ntest_y_denorm = scaler2.inverse_transform(test_y.reshape(-1,1))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:23:13.63297Z","iopub.execute_input":"2021-12-03T13:23:13.633247Z","iopub.status.idle":"2021-12-03T13:23:14.712221Z","shell.execute_reply.started":"2021-12-03T13:23:13.633218Z","shell.execute_reply":"2021-12-03T13:23:14.71115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(test_pred_y,color='red', label='Prediction')\nplt.plot(test_y_denorm,color='blue', label='Actual')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:23:19.01486Z","iopub.execute_input":"2021-12-03T13:23:19.015313Z","iopub.status.idle":"2021-12-03T13:23:19.241284Z","shell.execute_reply.started":"2021-12-03T13:23:19.01528Z","shell.execute_reply":"2021-12-03T13:23:19.240095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loss graph**","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:23:56.066295Z","iopub.execute_input":"2021-12-03T13:23:56.066576Z","iopub.status.idle":"2021-12-03T13:23:56.276991Z","shell.execute_reply.started":"2021-12-03T13:23:56.066549Z","shell.execute_reply":"2021-12-03T13:23:56.27595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\ndef model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]\n\nmodel_score(model, train_X, train_y , test_X, test_y)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:24:00.184344Z","iopub.execute_input":"2021-12-03T13:24:00.184619Z","iopub.status.idle":"2021-12-03T13:24:01.669695Z","shell.execute_reply.started":"2021-12-03T13:24:00.18459Z","shell.execute_reply":"2021-12-03T13:24:01.668759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential () \n\nmodel.add(LSTM(256, input_shape=(seq_len,1), return_sequences=True))\nmodel.add(LSTM(128,return_sequences=False))\nmodel.add(Dense(1, activation = 'relu'))\nmodel.compile(loss='mse',optimizer='adam', metrics=['mae'])\nhistory = model.fit(train_X,train_y,batch_size=512, epochs=90,verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential () \n\nmodel.add(LSTM(256, input_shape=(seq_len,1), return_sequences=True))\nmodel.add(LSTM(128,return_sequences=False))\nmodel.add(Dense(1, activation = 'relu'))\nmodel.compile(loss='mse',optimizer='adam', metrics=['mae'])\nhistory = model.fit(train_X,train_y,batch_size=512, epochs=90,verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimizer**","metadata":{}},{"cell_type":"code","source":"time_stamp = 1 # predict days\nseq_len = [5,10,22] # backtracking num of days\nlstm_layers = [1,2,3]\ndense_layers = [1,2,3]\nnode_num = [64,128,256]# number of nodes each layer\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfor md in mem_days:\n    for ll in lstm_layers:\n        for dl in dense_layers:\n            for nn in node_num:\n                filepath = './models/{val_mape:.2f}_{epoch:02d}_'+f'mem_{md}_lstm{ll}_dense{dl}_node{nn}'\n                checkpoint = ModelCheckpoint(\n                    filepath = filepath,\n                    save_weights_only=False,\n                    monitor='val_mape',\n                    mode='min',\n                    save_best_only=True)\n                \n                X,y,X_latest = dataset(df2, md, time_stßamp)\n                X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle = False, test_size = 0.1)\n                \n                model = Sequential()\n                model.add(LSTM(nn, input_shape = X.shape[1:], activation = 'relu', return_sequences = True))\n                model.add(Dropout(0.1)) # avoid overfitting\n                \n                for i in range(ll):\n                    model.add(LSTM(nn, activation = 'relu', return_sequences = True))\n                    model.add(Dropout(0.1))\n                \n                model.add(LSTM(nn, activation = 'relu', return_sequences = True))\n                model.add(Dropout(0.1))\n                \n                for i in range(dl):\n                    model.add(Dense(nn, activation = 'relu')) # 32\n                    model.add(Dropout(0.1))\n\n                model.add(Dense(1)) # output layer\n                                                 # cuz linear regression\n                model.compile(optimizer = 'adam', loss= 'mse', metrics = ['mape'])\n                \n                model.fit(X_train, y_train,batch_size = 32, epochs=50, validation_data=(X_test,y_test),callbacks=[checkpoint]) ","metadata":{},"execution_count":null,"outputs":[]}]}